{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "## The Blocker Fraud Company\n",
    "\n",
    "**Blocker Fraud Company** is a specialized company in fraud detection on financial transactions through mobile devices. It has the \"Blocker Fraud\" service, which guarantee the block of fraudulent transactions.\n",
    "\n",
    "The company business model is service type, with monetization made by performance of the provided service. The user pay a fixed fee on the fraud detection success.\n",
    "\n",
    "## Expansion Strategy in Brazil\n",
    "\n",
    "Aiming to expand business in Brazil it has adopted the following strategy:\n",
    "\n",
    "- The company will receive 25% of the value of each transaction detected as *fraud*.\n",
    "- The company will receive 5% of the value of each transaction detected as *fraud*, but the transaction is *legitimate*.\n",
    "- The company will return 100% of the value to the customer, for each transaction detected as legitimate, however a transaction is a fraud.\n",
    "\n",
    "## Context\n",
    "\n",
    "There is a lack of public available datasets on financial services and specially in the emerging mobile money transactions domain. Financial datasets are important to many researchers and in particular to us performing research in the domain of fraud detection. Part of the problem is the intrinsically private nature of financial transactions, that leads to no publicly available datasets.\n",
    "\n",
    "We present a synthetic dataset generated using the simulator called PaySim as an approach to such a problem. PaySim uses aggregated data from the private dataset to generate a synthetic dataset that resembles the normal operation of transactions and injects malicious behavior to later evaluate the performance of fraud detection methods.\n",
    "\n",
    "## Content\n",
    "\n",
    "PaySim simulates mobile money transactions based on a sample of real transactions extracted from one month of financial logs from a mobile money service implemented in an African country. The original logs were provided by a multinational company, who is the provider of the mobile financial service which is currently running in more than 14 countries all around the world.\n",
    "\n",
    "This synthetic dataset is scaled down 1/4 of the original dataset and it is created just for Kaggle.\n",
    "\n",
    "## Goal\n",
    "\n",
    "1. What is the model's *precision* and *accuracy*?\n",
    "2. How reliable is the model in classifying transactions as *legitimate* or *fraudulent*?\n",
    "3. What is the expected billing by the company if we classify 100% of data transactions with the model?\n",
    "4. What is the loss expected by company in case of model failure ?\n",
    "5. What is the profit expected by the **Blocker Fraud Company** when using model?\n",
    "> Disclaimer: The following context is completely fictional, the company, the context, the CEO and the business questions.\n",
    "\n",
    "## Data\n",
    "\n",
    "Data provided by Kaggle: [Synthetic Financial Datasets for Fraud Detection](https://www.kaggle.com/ntnu-testimon/paysim1)\n",
    "\n",
    "## Analysis\n",
    "\n",
    "This solution will use descriptive statistics and data visualization to find key figures in understanding the distribution, count, and relationship between variables. Since the goal of the project to make predictions on the fraud's detection, classification algorithms from the supervised learning family of machine learning models will be implemented.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "The project will conclude with the evaluation of the machine learning model selected with a validation data set. The output of the predictions can be checked through a confusion matrix, and metrics such as accuracy, precision, recall, F1 and Kappa scores."
   ]
  },
  {
   "source": [
    "# 0.0. Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistics\n",
    "from scipy import stats\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# Graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load images\n",
    "from IPython.display import Image\n",
    "\n",
    "# Warning\n",
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "\n",
    "# Feature selection\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# Stats\n",
    "from scipy import stats\n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Save files\n",
    "import pickle\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Model's cross-validation\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, cross_val_predict, RandomizedSearchCV,\\\n",
    "GridSearchCV\n",
    "\n",
    "# Model's metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\\\n",
    "confusion_matrix, matthews_corrcoef, make_scorer, roc_curve, classification_report, auc\n",
    "\n",
    "# Handling Oversampling\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "source": [
    "## 0.1. Help Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentual plot\n",
    "def percentual_count(var: str, dataset: pd.DataFrame):\n",
    "    ax = sns.countplot(y=var, data=dataset)\n",
    "    total = len(dataset[var])\n",
    "    for p in ax.patches:\n",
    "            percentage = '{:.1f}%'.format(100 * p.get_width()/total)\n",
    "            x = p.get_x() + p.get_width() + 0.02\n",
    "            y = p.get_y() + p.get_height()/2\n",
    "            ax.annotate(percentage, (x, y))\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramers_corrected_stat(x, y):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "    \"\"\"\n",
    "    # Calculate confusion matrix\n",
    "    cm = pd.crosstab(x, y).values\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "\n",
    "    # Calculate chi2\n",
    "    chi2 = stats.chi2_contingency(cm)[0]\n",
    "    # Calculate chi2 correction\n",
    "    chi2corr = max(0, chi2 - (k-1)*(r-1)/(n-1))\n",
    "    # K correction\n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    # R correction\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    \n",
    "    return np.sqrt((chi2corr/n) / (min(kcorr-1, rcorr-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's performance\n",
    "def ml_scores(model_name, y_test, y_pred):\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    return pd.DataFrame({'Accuracy': accuracy, \n",
    "                         'Precision': precision, \n",
    "                         'Recall': recall,\n",
    "                         'F1': f1,\n",
    "                         'ROC': roc}, \n",
    "                        index=[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's performance function\n",
    "def cross_val_performance(model, y_train, y_pred):\n",
    "    # define scoring metrics\n",
    "    scoring = {'Accuracy': 'accuracy',\n",
    "               'Precision': make_scorer(precision_score),\n",
    "               'Recall': make_scorer(recall_score),\n",
    "               'F1': make_scorer(f1_score),\n",
    "               'ROC': make_scorer(roc_auc_score)}\n",
    "\n",
    "    # calculate scores with cross_validate\n",
    "    scores = cross_validate(model, y_train, y_pred, cv=10, scoring=scoring)\n",
    "\n",
    "    # performance data frame\n",
    "    performance = pd.DataFrame.from_dict(scores).drop(['fit_time', 'score_time'], axis=1)\n",
    "    performance = pd.DataFrame(np.round(performance.mean(), 4).astype(str) + ' +/- ' + np.round(performance.std()*2,4).astype(str)).T\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix function\n",
    "def conf_matrix(y_train, y_pred):\n",
    "    cm = confusion_matrix(y_train, y_pred)\n",
    "    cm_data = pd.DataFrame(cm, columns = ['Positive', 'Negative'], index=['Positive', 'Negative'])\n",
    "    sns.heatmap(cm_data, annot=True, cmap='Blues', fmt='d', annot_kws={'size': 24}).set_title('Confusion Matrix')\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}